pacman::p_load(DIDmultiplegt)
# Data
# load dataset + filter
analysis_sample <- read_dta("../original_study/labour-market/data/output/analysis_sample.dta") %>%
filter(twfe_sample == 1)
# Script
# ==============================================================================
# create_exhbits_do (creating macro) ----
eqopp_demos <- c("k_married", "par_q1", "par_q2", "par_q3", "par_q4", "par_d9",
"par_top10pc", "par_top5pc", "par_top1pc", "par_toppt1pc", "par_rank")
ipeds_demos <- c("female", "hispanic", "asian", "black", "nativeamerican", "alien", "unknown",
"satmt25", "satmt75", "mi_sat", "use_act_score", "admssn_rate", "mi_admission_rate")
major_controls <- grep("^major_", names(analysis_sample), value = TRUE)
major_controls <- c(major_controls, "gradrate_150p")
### TWOWAYFE.do ----
#modify k rank variable
analysis_sample$k_rank <- analysis_sample$k_rank * 100
analysis_sample$cohort
min(analysis_sample$cohort)
max(analysis_sample$cohort)
min(analysis_sample$cohort)[exposure==1]
min(analysis_sample$cohort)[analysis_sample$exposure==1]
min(analysis_sample$cohort)[[analysis_sample$exposure==1]]
analysis_sample$exposure==1
min(analysis_sample$cohort)[[analysis_sample$EXPOSED==1]]
min(analysis_sample$cohort)[[analysis_sample$EXPOSED=1]]
min(analysis_sample$cohort[analysis_sample$EXPOSED == 1])
max(analysis_sample$cohort[analysis_sample$EXPOSED == 1])
min(analysis_sample$AY_FALL[analysis_sample$EXPOSED == 1])
max(analysis_sample$AY_FALL[analysis_sample$EXPOSED == 1])
min(analysis_sample$cohort)
max(analysis_sample$cohort)
min(analysis_sample$cohort[analysis_sample$EXPOSED == 1])
max(analysis_sample$cohort[analysis_sample$EXPOSED == 1])
min(analysis_sample$AY_FALL)
max(analysis_sample$AY_FALL)
min(analysis_sample$AY_FALL[analysis_sample$EXPOSED == 1])
max(analysis_sample$AY_FALL[analysis_sample$EXPOSED == 1])
source("~/.active-rstudio-document")
source("~/.active-rstudio-document")
source("~/Documents/R_folder/MSc/ME/ME-project/code/1.5-plot.R")
df <- read_dta("../original_study/labour-market/data/output/analysis_sample.dta")
# Assuming 'df' is your DataFrame after loading the data
# Keep the necessary columns
df <- df %>% select(simpletier, DateJoinedFB, FBName, super_opeid, barrons, UNITID)
# Handle duplicates and convert the date format
df <- df %>% distinct() %>% mutate(date = mdy(DateJoinedFB))
rm(list=ls())
df <- read_dta("../original_study/labour-market/data/output/analysis_sample.dta")
# Assuming 'df' is your DataFrame after loading the data
# Keep the necessary columns
df <- df %>% select(simpletier, DateJoinedFB, FBName, super_opeid, barrons, UNITID)
# Handle duplicates and convert the date format
df <- df %>% distinct() %>% mutate(date = mdy(DateJoinedFB))
# Create a sequence of dates
date_seq <- seq(from = min(df$date, na.rm = TRUE), to = max(df$date, na.rm = TRUE), by = "day")
# Initialize a list to store data frames for each tier
tier_data <- list()
# Loop over each tier to calculate fraction of schools with FB access
tiers <- unique(df$barrons)
for(t in tiers) {
# For each date, calculate the fraction of schools that have joined FB
tier_df <- data.frame(date = date_seq)
tier_df$fb_access <- sapply(tier_df$date, function(d) {
mean(df$date <= d & df$barrons == t, na.rm = TRUE)
})
tier_df$tier = t
tier_data[[as.character(t)]] <- tier_df
}
# Combine all tiers into one data frame
combined_df <- bind_rows(tier_data)
# Plotting
ggplot(combined_df, aes(x = date, y = fb_access, color = factor(tier))) +
geom_line() +
labs(title = "Facebook Rollout Across School Tiers",
x = "Date",
y = "Fraction of Schools with FB Access",
color = "Tier") +
theme_minimal() +
scale_color_manual(values = c("red", "blue", "green", "yellow", "purple", "orange")) # Customize as needed
source("~/Documents/R_folder/MSc/ME/ME-project/code/1.5-plot.R")
setwd("~/Documents/R_folder/MSc/ME/ME-project/original_study/labour-market")
# Import data
cohort_graphdata <- read_csv("data/output/cohort_graphdata.csv")
analysis_sample <- read_csv("data/output/analysis_sample.csv")
analysis_sample <- read_dta("data/output/analysis_sample.dta")
# Replace missing values and merge
analysis_sample <- analysis_sample %>%
mutate(sat_math = if_else(mi_sat == 1, NA_real_, sat_math)) %>%
left_join(cohort_graphdata, by = "UNITID") # Adjust join type and by clause as necessary
analysis_sample$EXPOSURE_4YR
summary(analysis_sample$EXPOSURE_4YR)
head(analysis_sample)
head(analysis_sample$EXPOSURE_4YR))
summary(analysis_sample$EXPOSURE_4YR)
head(analysis_sample$EXPOSURE_4YR)
getwd()
setwd("~/Documents/R_folder/MSc/ME/ME-project")
source("~/Documents/R_folder/MSc/ME/ME-project/code/1.prelim-DiD.R")
df <- read_dta("../original_study/labour-market/data/output/analysis_sample.dta") %>%
filter(twfe_sample == 1)
# ------------------------------------------
#           Staggered DiD Script
# ------------------------------------------
rm(list = ls())
# Install DIDmultiplegt from GitHub if not already installed
if (!"HonestDiD" %in% rownames(installed.packages())) {
remotes::install_github("asheshrambachan/HonestDiD")
}
# Load DIDmultiplegt
pacman::p_load(DIDmultiplegt, readr)
# cohort_earn_panel
class(df$k_married)
rm(list = ls())
# Install DIDmultiplegt from GitHub if not already installed
if (!"HonestDiD" %in% rownames(installed.packages())) {
remotes::install_github("asheshrambachan/HonestDiD")
}
# Load DIDmultiplegt
pacman::p_load(DIDmultiplegt, readr)
# cohort_earn_panel
class(df$k_married)
Y <- "k_rank"
Y <- "k_rank"
G <- "UNITID"
T <- "AY_FALL"
D <- "EXPOSED"
head <- df %>% select(all_of(Y), all_of(T), all_of(D), all_of(G))
rm(list = ls())
library(here)
library(dplyr)
library(did)
library(haven)
library(ggplot2)
library(fixest)
library(HonestDiD)
library(readr)
library(pacman)
# Install DIDmultiplegt from GitHub if not already installed
if (!"HonestDiD" %in% rownames(installed.packages())) {
remotes::install_github("asheshrambachan/HonestDiD")
}
# Load DIDmultiplegt
pacman::p_load(DIDmultiplegt, readr)
Y <- "k_rank"
G <- "UNITID"
T <- "AY_FALL"
D <- "EXPOSED"
head <- df %>% select(all_of(Y), all_of(T), all_of(D), all_of(G))
df <- read_dta("../original_study/labour-market/data/output/analysis_sample.dta") %>%
filter(twfe_sample == 1)
df1 <- read_dta("../original_study/labour-market/data/output/analysis_sample.dta") %>%
filter(main_sample == 1)
df$main_sample
source("~/Documents/R_folder/MSc/ME/ME-project/code/2-staggered.R")
df1 <- read_dta("../original_study/labour-market/data/output/analysis_sample.dta") %>%
filter(main_sample == 1)
#Create a treatment dummy
df = df_nonstaggered
#Create a treatment dummy
df = df_nonstaggered
#Create a treatment dummy
df_nonstaggered = df
df_nonstaggered <- df_nonstaggered %>% mutate(D = case_when( yexp2 == 2014 ~ 1,
T ~ 0))
#Create a treatment dummy
df_nonstaggered = df
df_nonstaggered <- df_nonstaggered %>% mutate(D = EXPOSED) #binary for >=30 days facebook rollout in cohort-year
year = "AY_FALL"
#Run the TWFE spec
twfe_results <- fixest::feols(k_rank ~ i(AY_FALL, D, ref = 2004) | stfips + AY_FALL,
cluster = "UNITID",
data = df_nonstaggered)
#Run the TWFE spec
twfe_results <- fixest::feols(k_rank ~ i(AY_FALL, D, ref = 2004) | UNITID + AY_FALL,
cluster = "UNITID",
data = df_nonstaggered)
betahat <- summary(twfe_results)$coefficients #save the coefficients
sigma <- summary(twfe_results)$cov.scaled #save the covariance matrix
fixest::iplot(twfe_results)
#Run the TWFE spec
twfe_results <- fixest::feols(k_rank ~ i(AY_FALL, D, ref = 2003) | UNITID + AY_FALL,
cluster = "UNITID",
data = df_nonstaggered)
betahat <- summary(twfe_results)$coefficients #save the coefficients
sigma <- summary(twfe_results)$cov.scaled #save the covariance matrix
fixest::iplot(twfe_results)
source("~/Documents/R_folder/MSc/ME/ME-project/code/1.prelim-DiD.R")
source("~/Documents/R_folder/MSc/ME/ME-project/code/2-staggered.R")
independent_vars_m2
# Dynamically construct your formula for m2 (same as m1 if variables are unchanged)
independent_vars_m2 <- c("EXPOSED", eqopp_demos, ipeds_demos)
independent_vars_m2
#Run the TWFE spec
independent_vars_m2 <- c("EXPOSED", "k_married", eqopp_demos, ipeds_demos)
#Create a treatment dummy
df_nonstaggered = df
df_nonstaggered <- df_nonstaggered %>% mutate(D = EXPOSED) #binary for >=30 days facebook rollout in cohort-year
#Run the TWFE spec
independent_vars_m2 <- c("EXPOSED", "k_married", eqopp_demos, ipeds_demos)
# ------------------------------------------
#           Staggered DiD Script
# ------------------------------------------
rm(list = ls())
library(here)
library(dplyr)
library(did)
library(haven)
library(ggplot2)
library(fixest)
library(HonestDiD)
library(readr)
library(pacman)
# Install DIDmultiplegt from GitHub if not already installed
if (!"HonestDiD" %in% rownames(installed.packages())) {
remotes::install_github("asheshrambachan/HonestDiD")
}
# Load DIDmultiplegt
pacman::p_load(DIDmultiplegt, readr)
df <- read_dta("../original_study/labour-market/data/output/analysis_sample.dta") %>%
filter(twfe_sample == 1)
# df1 <- read_dta("../original_study/labour-market/data/output/analysis_sample.dta") %>%
#   filter(main_sample == 1)
source("~/Documents/R_folder/MSc/ME/ME-project/code/1.prelim-DiD.R")
Y <- "k_rank"
G <- "UNITID"
T <- "AY_FALL"
D <- "EXPOSED"
###
# Define your variable lists
eqopp_demos <- c("k_married", "par_q1", "par_q2", "par_q3", "par_q4", "par_d9",
"par_top10pc", "par_top5pc", "par_top1pc", "par_toppt1pc", "par_rank")
ipeds_demos <- c("female", "hispanic", "asian", "black", "nativeamerican", "alien", "unknown",
"satmt25", "satmt75", "mi_sat", "use_act_score", "admssn_rate", "mi_admission_rate")
# Assuming 'analysis_sample' was a mistake and your dataframe is 'df', let's adjust that:
major_controls <- grep("^major_", names(df), value = TRUE)
simpletiershock_star <- grep("^simpletiershock_", names(df), value = TRUE)
# Append 'gradrate_150p' to 'major_controls'
major_controls <- c(major_controls, "gradrate_150p")
# Combine all controls for a full check
controls <- c(eqopp_demos, ipeds_demos, major_controls, simpletiershock_star)
# Define individual variables
Y <- "k_rank"
G <- "UNITID"
T <- "AY_FALL"
D <- "EXPOSED"
# Function to check and print variables not in dataframe
check_vars_in_df <- function(var_list, df) {
not_present <- var_list[!var_list %in% names(df)]
if(length(not_present) > 0) {
return(not_present)
} else {
return("All variables are present.")
}
}
# Perform checks
eqopp_check <- check_vars_in_df(eqopp_demos, df)
ipeds_check <- check_vars_in_df(ipeds_demos, df)
controls_check <- check_vars_in_df(controls, df)
individual_vars_check <- check_vars_in_df(c(Y, G, T, D), df)
# missing the following variables (since only replicated 1 file cleaning)
list(eqopp_check = eqopp_check, ipeds_check = ipeds_check, controls_check = controls_check, individual_vars_check = individual_vars_check)
head <- df %>% select(all_of(Y), all_of(T), all_of(D), all_of(G))
#Create a treatment dummy
df_nonstaggered = df
df_nonstaggered <- df_nonstaggered %>% mutate(D = EXPOSED) #binary for >=30 days facebook rollout in cohort-year
#Run the TWFE spec
independent_vars_m2 <- c("EXPOSED", "k_married", eqopp_demos, ipeds_demos)
# Creating the formula string
formula_str_m2 <- paste("k_rank ~", paste(independent_vars_m2, collapse = " + "), "| UNITID + simpletiershock")
m2 <- feols(as.formula(formula_str_m2), data = df_nonstaggered, vcov = ~UNITID)
betahat_m2 <- summary(m2)$coefficients #save the coefficients for m2
sigma_m2 <- summary(m2)$cov.scaled #save the covariance matrix for m2
fixest::iplot(m2)
m2 <- feols(as.formula(formula_str_m2), data = df_nonstaggered, vcov = ~UNITID)
df_nonstaggered %>% mutate(D = EXPOSED)
#Create a treatment dummy
df_nonstaggered = df
df <- read_dta("../original_study/labour-market/data/output/analysis_sample.dta") %>%
filter(twfe_sample == 1)
rm(list = ls())
library(here)
library(dplyr)
library(did)
rm(list = ls())
library(here)
library(dplyr)
library(did)
library(haven)
library(ggplot2)
library(fixest)
library(HonestDiD)
library(readr)
library(pacman)
# Install DIDmultiplegt from GitHub if not already installed
if (!"HonestDiD" %in% rownames(installed.packages())) {
remotes::install_github("asheshrambachan/HonestDiD")
}
# Load DIDmultiplegt
pacman::p_load(DIDmultiplegt, readr)
df <- read_dta("../original_study/labour-market/data/output/analysis_sample.dta") %>%
filter(twfe_sample == 1)
source("~/Documents/R_folder/MSc/ME/ME-project/code/1.prelim-DiD.R")
Y <- "k_rank"
G <- "UNITID"
T <- "AY_FALL"
D <- "EXPOSED"
# Define your variable lists
eqopp_demos <- c("k_married", "par_q1", "par_q2", "par_q3", "par_q4", "par_d9",
"par_top10pc", "par_top5pc", "par_top1pc", "par_toppt1pc", "par_rank")
ipeds_demos <- c("female", "hispanic", "asian", "black", "nativeamerican", "alien", "unknown",
"satmt25", "satmt75", "mi_sat", "use_act_score", "admssn_rate", "mi_admission_rate")
# Assuming 'analysis_sample' was a mistake and your dataframe is 'df', let's adjust that:
major_controls <- grep("^major_", names(df), value = TRUE)
simpletiershock_star <- grep("^simpletiershock_", names(df), value = TRUE)
rm(list = ls())
source("~/Documents/R_folder/MSc/ME/ME-project/code/1.prelim-DiD.R")
library(here)
library(dplyr)
library(did)
library(haven)
library(ggplot2)
library(fixest)
library(HonestDiD)
library(readr)
library(pacman)
# Install DIDmultiplegt from GitHub if not already installed
if (!"HonestDiD" %in% rownames(installed.packages())) {
remotes::install_github("asheshrambachan/HonestDiD")
}
# Load DIDmultiplegt
pacman::p_load(DIDmultiplegt, readr)
df <- read_dta("../original_study/labour-market/data/output/analysis_sample.dta") %>%
filter(twfe_sample == 1)
Y <- "k_rank"
G <- "UNITID"
T <- "AY_FALL"
D <- "EXPOSED"
# Define your variable lists
eqopp_demos <- c("k_married", "par_q1", "par_q2", "par_q3", "par_q4", "par_d9",
"par_top10pc", "par_top5pc", "par_top1pc", "par_toppt1pc", "par_rank")
ipeds_demos <- c("female", "hispanic", "asian", "black", "nativeamerican", "alien", "unknown",
"satmt25", "satmt75", "mi_sat", "use_act_score", "admssn_rate", "mi_admission_rate")
# Assuming 'analysis_sample' was a mistake and your dataframe is 'df', let's adjust that:
major_controls <- grep("^major_", names(df), value = TRUE)
simpletiershock_star <- grep("^simpletiershock_", names(df), value = TRUE)
# Append 'gradrate_150p' to 'major_controls'
major_controls <- c(major_controls, "gradrate_150p")
# Combine all controls for a full check
controls <- c(eqopp_demos, ipeds_demos, major_controls, simpletiershock_star)
# Define individual variables
Y <- "k_rank"
G <- "UNITID"
T <- "AY_FALL"
D <- "EXPOSED"
# Function to check and print variables not in dataframe
check_vars_in_df <- function(var_list, df) {
not_present <- var_list[!var_list %in% names(df)]
if(length(not_present) > 0) {
return(not_present)
} else {
return("All variables are present.")
}
}
# Perform checks
eqopp_check <- check_vars_in_df(eqopp_demos, df)
ipeds_check <- check_vars_in_df(ipeds_demos, df)
controls_check <- check_vars_in_df(controls, df)
individual_vars_check <- check_vars_in_df(c(Y, G, T, D), df)
# missing the following variables (since only replicated 1 file cleaning)
list(eqopp_check = eqopp_check, ipeds_check = ipeds_check, controls_check = controls_check, individual_vars_check = individual_vars_check)
head <- df %>% select(all_of(Y), all_of(T), all_of(D), all_of(G))
head(head)
head(df, 5)
#Create a treatment dummy
df_nonstaggered = df
df_nonstaggered <- df_nonstaggered %>% mutate(D = EXPOSED) #binary for >=30 days facebook rollout in cohort-year
#Run the TWFE spec
independent_vars_m2 <- c("EXPOSED", "k_married", eqopp_demos, ipeds_demos)
# Creating the formula string
formula_str_m2 <- paste("k_rank ~", paste(independent_vars_m2, collapse = " + "), "| UNITID + simpletiershock")
m2 <- feols(as.formula(formula_str_m2), data = df_nonstaggered, vcov = ~UNITID)
betahat_m2 <- summary(m2)$coefficients #save the coefficients for m2
sigma_m2 <- summary(m2)$cov.scaled #save the covariance matrix for m2
fixest::iplot(m2)
independent_vars_m2
formula_str_m2
formula_str <- paste("k_rank ~", paste(independent_vars, collapse = " + "), "| UNITID" + simpletiershock_star)
analysis_sample
#Run the TWFE spec
independent_vars_m2 <- c("EXPOSED", "k_married", eqopp_demos, ipeds_demos)
# Creating the formula string
formula_str_m2 <- paste("k_rank ~", paste(independent_vars_m2, collapse = " + "), "| UNITID + simpletiershock")
m2 <- feols(as.formula(formula_str_m2), data = df_nonstaggered, vcov = ~UNITID)
m2 <- feols(as.formula(formula_str_m2), data = analysis_sample, vcov = ~UNITID)
betahat_m2 <- summary(m2)$coefficients #save the coefficients for m2
sigma_m2 <- summary(m2)$cov.scaled #save the covariance matrix for m2
fixest::iplot(m2)
plot(m2)
m2 <- feols(as.formula(formula_str_m2), data = analysis_sample, vcov = ~UNITID)
betahat_m2 <- summary(m2)$coefficients #save the coefficients for m2
sigma_m2 <- summary(m2)$cov.scaled #save the covariance matrix for m2
plot(m2)
View(m2)
analysis_sample$simpletiershock
# Creating the formula string
# Including year fixed effects using i(year, ref = referenceYear) if you want to specify a reference year
# Adding treatment effect if EXPOSED varies over time or across units could be done via interactions, if necessary
formula_str_m2 <- paste("k_rank ~ EXPOSED +", paste(independent_vars_m2, collapse = " + "), "+ i(AY_FALL)", "| UNITID + simpletiershock")
formula_str_m2
#Run the TWFE spec
#Run the TWFE spec
twfe_results <- fixest::feols(k_rank ~ i(AY_FALL, EXPOSED, ref = 2013) | UNITID + AY_FALL,
cluster = "UNITID",
data = df_nonstaggered)
#Run the TWFE spec
#Run the TWFE spec
twfe_results <- fixest::feols(k_rank ~ i(AY_FALL, EXPOSED) | UNITID + AY_FALL,
cluster = "UNITID",
data = df_nonstaggered)
betahat <- summary(twfe_results)$coefficients #save the coefficients
sigma <- summary(twfe_results)$cov.scaled #save the covariance matrix
fixest::iplot(twfe_results)
twfe_results
# Estimate the baseline DiD model - PULKIT
library(haven)
library(tidyverse)
library(fixest)
library(fastDummies)
library(lmtest)
analysis_sample <- read_dta("../original_study/labour-market/data/output/analysis_sample.dta") %>%
filter(twfe_sample == 1 & late_adopter == 0)
analysis_sample$k_rank <- analysis_sample$k_rank * 100
#excluding a specific observation
analysis_sample <- filter(analysis_sample, UNITID != 184694)
# create + recode simplebarrons variable
analysis_sample$simplebarrons <- analysis_sample$barrons
analysis_sample$simplebarrons <- as.numeric(as.character(analysis_sample$simplebarrons))
analysis_sample$simplebarrons <- dplyr::recode(analysis_sample$simplebarrons,
`0` = 1, `1` = 1,
`2` = 2, `3` = 2,
`4` = 3,
`5` = 4,
`999` = 9)
# group data and generate identifiers
analysis_sample$simpletiershock <- as.integer(interaction(analysis_sample$simplebarrons, analysis_sample$AY_FALL, drop = TRUE))
analysis_sample <- fastDummies::dummy_cols(analysis_sample, select_columns = "simpletiershock")
analysis_sample$D <- ifelse(analysis_sample$EXPOSURE_4YR > 0, 1, 0)
analysis_sample <- analysis_sample %>% mutate(t = case_when(
AY_FALL == 1998 ~ 1,
AY_FALL == 1999 ~ 2,
AY_FALL == 2000 ~ 3,
AY_FALL == 2001 ~ 4,
AY_FALL == 2002 ~ 5,
AY_FALL == 2003 ~ 6,
AY_FALL == 2004 ~ 7,
AY_FALL == 2005 ~ 8
))
analysis_sample$G <- 0
for (i in unique(analysis_sample$UNITID)){
analysis_sample$G[analysis_sample$UNITID == i] <- min(analysis_sample$t[analysis_sample$UNITID == i & analysis_sample$D == 1])
}
analysis_sample$R <- analysis_sample$t - analysis_sample$G + 1
analysis_sample <- dummy_cols(analysis_sample, select_columns = "R")
R <- grep("R_", names(analysis_sample)[300:374], value = T)
# static TWFE
M1 <- feols(k_rank ~ D | UNITID + simpletiershock, data = analysis_sample, vcov = "cluster")
print(M1)
print(M2)
# dynamic TWFE
M2 <- feols(k_rank ~ `R_-1` + `R_-2` + `R_1` + `R_2` + `R_3` + `R_4` + `R_5` +
`R_6` | UNITID + simpletiershock, data = analysis_sample, vcov = "cluster")
print(M2)
source("~/Documents/R_folder/MSc/ME/ME-project/code/1.5-plot.R")
## FIGURE 1 ------------------------------------------
# Load necessary libraries
library(tidyverse)
library(lubridate)
rm(list=ls())
df <- read_dta("../original_study/labour-market/data/output/analysis_sample.dta")
# Keep the necessary columns
df <- df %>% select(simpletier, DateJoinedFB, FBName, super_opeid, barrons, UNITID)
# Handle duplicates and convert the date format
df <- df %>% distinct() %>% mutate(date = mdy(DateJoinedFB))
# Create a sequence of dates
date_seq <- seq(from = min(df$date, na.rm = TRUE), to = max(df$date, na.rm = TRUE), by = "day")
# Initialize a list to store data frames for each tier
tier_data <- list()
# Loop over each tier to calculate fraction of schools with FB access
tiers <- unique(df$barrons)
for(t in tiers) {
# For each date, calculate the fraction of schools that have joined FB
tier_df <- data.frame(date = date_seq)
tier_df$fb_access <- sapply(tier_df$date, function(d) {
mean(df$date <= d & df$barrons == t, na.rm = TRUE)
})
tier_df$tier = t
tier_data[[as.character(t)]] <- tier_df
}
# Combine all tiers into one data frame
combined_df <- bind_rows(tier_data)
# Plotting
ggplot(combined_df, aes(x = date, y = fb_access, color = factor(tier))) +
geom_line() +
labs(title = "Facebook Rollout Across School Tiers",
x = "Date",
y = "Fraction of Schools with FB Access",
color = "Tier") +
theme_minimal() +
scale_color_manual(values = c("red", "blue", "green", "yellow", "purple", "orange")) # Customize as needed
# Save the plot
#ggsave("fb_rollout.pdf", width = 11, height = 8.5, dpi = 300)
